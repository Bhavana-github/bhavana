{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_CNN_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9EU0e8yzFOm",
        "colab_type": "code",
        "outputId": "8bfd06c5-5a32-45f9-ced6-4c14b3477bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "# Credits: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(5, 5),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0720 10:27:32.720910 139827260249984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0720 10:27:32.735783 139827260249984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0720 10:27:32.738632 139827260249984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0720 10:27:32.780340 139827260249984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0720 10:27:32.783479 139827260249984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0720 10:27:32.794621 139827260249984 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0720 10:27:32.900683 139827260249984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0720 10:27:32.911315 139827260249984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0720 10:27:33.014470 139827260249984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 1.7602 - acc: 0.4263 - val_loss: 0.7243 - val_acc: 0.7833\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.8596 - acc: 0.7436 - val_loss: 0.3801 - val_acc: 0.8861\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.6774 - acc: 0.8056 - val_loss: 0.3797 - val_acc: 0.8868\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.6195 - acc: 0.8264 - val_loss: 0.2553 - val_acc: 0.9250\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 276s 5ms/step - loss: 0.5999 - acc: 0.8363 - val_loss: 0.2745 - val_acc: 0.9225\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.5887 - acc: 0.8402 - val_loss: 0.3473 - val_acc: 0.8960\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.5756 - acc: 0.8458 - val_loss: 0.2102 - val_acc: 0.9419\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.5837 - acc: 0.8485 - val_loss: 0.2309 - val_acc: 0.9337\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.5941 - acc: 0.8477 - val_loss: 0.2281 - val_acc: 0.9345\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.5741 - acc: 0.8523 - val_loss: 0.2199 - val_acc: 0.9416\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.5999 - acc: 0.8464 - val_loss: 0.2392 - val_acc: 0.9293\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.5993 - acc: 0.8485 - val_loss: 0.2251 - val_acc: 0.9415\n",
            "Test loss: 0.2250828449747525\n",
            "Test accuracy: 0.9415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_CQqCL8JfUs",
        "colab_type": "text"
      },
      "source": [
        "discripction 1 : model is for 2 layer of conv with kernel size 5x5 and dropout. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufyNeeQJA04V",
        "colab_type": "text"
      },
      "source": [
        "obs: This model is of 2 hidden layer of conv with kernel size 5x5 and dropout,  model give accuracy of 0.9415 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ANSns2RKL4L",
        "colab_type": "code",
        "outputId": "e9c79f89-ebb5-464f-bf84-2874495c767c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Credits: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 199s 3ms/step - loss: 0.4635 - acc: 0.8579 - val_loss: 0.0748 - val_acc: 0.9766\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 199s 3ms/step - loss: 0.1344 - acc: 0.9610 - val_loss: 0.0658 - val_acc: 0.9804\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 199s 3ms/step - loss: 0.1030 - acc: 0.9693 - val_loss: 0.0400 - val_acc: 0.9888\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0885 - acc: 0.9745 - val_loss: 0.0329 - val_acc: 0.9897\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0795 - acc: 0.9771 - val_loss: 0.0282 - val_acc: 0.9916\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0680 - acc: 0.9804 - val_loss: 0.0407 - val_acc: 0.9879\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0633 - acc: 0.9816 - val_loss: 0.0258 - val_acc: 0.9919\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0598 - acc: 0.9826 - val_loss: 0.0269 - val_acc: 0.9919\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 196s 3ms/step - loss: 0.0551 - acc: 0.9839 - val_loss: 0.0237 - val_acc: 0.9925\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0524 - acc: 0.9844 - val_loss: 0.0277 - val_acc: 0.9916\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 196s 3ms/step - loss: 0.0511 - acc: 0.9850 - val_loss: 0.0319 - val_acc: 0.9902\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0496 - acc: 0.9852 - val_loss: 0.0271 - val_acc: 0.9921\n",
            "Test loss: 0.027145070607995148\n",
            "Test accuracy: 0.9921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgVO0JSRhzEh",
        "colab_type": "text"
      },
      "source": [
        "discripction 2 : model is for 3 layer of conv with kernel size 3x3 , dropout and batch normalization ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KshLCzuSB8gO",
        "colab_type": "text"
      },
      "source": [
        "obs: This model is of 3 hidden layer of conv with kernel size 3x3 and dropout with batch normalization, model give accuracy of 0.9921."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SQdHoiukBXE",
        "colab_type": "code",
        "outputId": "a6495e23-4413-4b06-b034-c704d77f945d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(128, kernel_size=(7, 7),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (7, 7), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0721 05:32:33.187844 139961647605632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0721 05:32:33.230194 139961647605632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0721 05:32:33.241563 139961647605632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0721 05:32:33.299834 139961647605632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0721 05:32:33.304158 139961647605632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0721 05:32:33.319152 139961647605632 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0721 05:32:33.354423 139961647605632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0721 05:32:33.636268 139961647605632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0721 05:32:34.078749 139961647605632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0721 05:32:34.198931 139961647605632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 244s 4ms/step - loss: 0.2564 - acc: 0.9215 - val_loss: 0.0763 - val_acc: 0.9758\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 243s 4ms/step - loss: 0.0942 - acc: 0.9728 - val_loss: 0.0387 - val_acc: 0.9882\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 239s 4ms/step - loss: 0.0697 - acc: 0.9797 - val_loss: 0.0338 - val_acc: 0.9890\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 242s 4ms/step - loss: 0.0581 - acc: 0.9835 - val_loss: 0.0295 - val_acc: 0.9908\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 240s 4ms/step - loss: 0.0483 - acc: 0.9858 - val_loss: 0.0281 - val_acc: 0.9913\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 239s 4ms/step - loss: 0.0433 - acc: 0.9875 - val_loss: 0.0366 - val_acc: 0.9897\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 238s 4ms/step - loss: 0.0395 - acc: 0.9884 - val_loss: 0.0250 - val_acc: 0.9930\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 237s 4ms/step - loss: 0.0349 - acc: 0.9902 - val_loss: 0.0310 - val_acc: 0.9906\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 237s 4ms/step - loss: 0.0320 - acc: 0.9907 - val_loss: 0.0248 - val_acc: 0.9922\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 239s 4ms/step - loss: 0.0296 - acc: 0.9911 - val_loss: 0.0379 - val_acc: 0.9905\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 238s 4ms/step - loss: 0.0281 - acc: 0.9920 - val_loss: 0.0272 - val_acc: 0.9923\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 237s 4ms/step - loss: 0.0284 - acc: 0.9920 - val_loss: 0.0223 - val_acc: 0.9936\n",
            "Test loss: 0.022255278358073293\n",
            "Test accuracy: 0.9936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAEa0vRLCQhP",
        "colab_type": "text"
      },
      "source": [
        "discripction 3 : model is for 2 layer of conv with kernel size 7x7 , dropout and batch normalization ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4UUR-IHCmAE",
        "colab_type": "text"
      },
      "source": [
        "obs: This model is of 2 hidden layer of conv with kernel size 7x7 and dropout with batch normalization, model give accuracy of 0.9936."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssqKsbwqMZ4g",
        "colab_type": "code",
        "outputId": "06b9d8a9-2e87-41fd-c9a7-c77b145d965e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "    \n",
        "x = PrettyTable()\n",
        "\n",
        "x.field_names = [ \"Model\",\"Test loss\" ,\"ACCURACY\"]\n",
        "\n",
        "x.add_row([\"2 layer of conv with kernel size 5x5 and dropout\", 0.2250,  0.9415])\n",
        "x.add_row([\" 3 layer of conv with kernel size 3x3 , dropout and batch normalization\",0.0271 , 0.9921])\n",
        "x.add_row([\" 2 Layer of conv with kernel size 7x7 , dropout and batch normalization\",0.02225 , 0.9936])\n",
        "\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------+-----------+----------+\n",
            "|                                  Model                                  | Test loss | ACCURACY |\n",
            "+-------------------------------------------------------------------------+-----------+----------+\n",
            "|             2 layer of conv with kernel size 5x5 and dropout            |   0.225   |  0.9415  |\n",
            "|  3 layer of conv with kernel size 3x3 , dropout and batch normalization |   0.0271  |  0.9921  |\n",
            "|  2 Layer of conv with kernel size 7x7 , dropout and batch normalization |  0.02225  |  0.9936  |\n",
            "+-------------------------------------------------------------------------+-----------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}